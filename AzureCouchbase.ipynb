{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cb621e-902f-419f-85ed-14ab11d578b0",
   "metadata": {},
   "source": [
    "# Using Couchbase with Azure OpenAI\n",
    "\n",
    "Microsoft's **Azure OpenAI** integrates OpenAI's advanced artificial intelligence models into the Azure platform. Azure OpenAI provides a scalable and secure environment to run these powerful models, making it easier for organizations to integrate AI capabilities into their applications and services. Users can access pre-trained models or customize them to fit specific needs.\n",
    "\n",
    "This notebook provides an example of using Azure OpenAI with Couchbase as a vector database. We will embed the file 'CouchbaseWhitepaper.pdf' with Azure OpenAI, load and index it into Couchbase, and perform a semantic search on its contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f256902f-6b60-4c0b-a65e-0ec6f21ab5be",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ed677-9502-4586-b643-923b17fb1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install couchbase OpenAI pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd17a1-f295-437d-9863-62f42360f2d2",
   "metadata": {},
   "source": [
    "## Reading Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e933b-7183-4cf3-a4c8-4a43bcaf17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def read_file(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870cf07-76d9-4acd-be90-241349637473",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_file(\"CouchbaseWhitepaper.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32c10e-41bd-4770-ad2e-fb2dea17ca63",
   "metadata": {},
   "source": [
    "## Chunking the Text into Paragraphs\n",
    "\n",
    "We first need to break the paragraphs into searchable chunks. Here, the chunks are divided according to the appearance of '.' characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac250456-6d9c-4b64-8ca0-93fd5296875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n):\n",
    "    sentences = text.split(\".\")\n",
    "    chunks = []\n",
    "    curr_chunk = \"\"\n",
    "    i = 0\n",
    "    for sentence in sentences:\n",
    "        if i < n-1:\n",
    "            curr_chunk += sentence\n",
    "            i+=1\n",
    "        else:\n",
    "            curr_chunk += sentence\n",
    "            chunks.append(curr_chunk)\n",
    "            curr_chunk = ''\n",
    "            i = 0\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b829d-3583-4e17-bcd7-2c2695575a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_text(text,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f4e8c-c1df-443d-94ee-e7621e98051c",
   "metadata": {},
   "source": [
    "## Generating Embeddings\n",
    "\n",
    "Now, we will initialize Azure OpenAI and use it to generate embeddings for each chunk. These embeddings will store the semantic meaning of each chunk and enable us to perform a semantic similarity search.\n",
    "\n",
    "**Note:** You can find your Azure key and endpoint on your Azure dashboard. You need to create a deployment with the 'text-embedding-model-ada' model before proceeding with this section of the cookbook.\n",
    "\n",
    "You can find documentation on how to set this up here: https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/deployment-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f2fac-3bac-4068-a5b0-67628876b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(client, documents):\n",
    "    embeddings = []\n",
    "    for doc in documents:\n",
    "        response = client.embeddings.create(\n",
    "            input=doc,\n",
    "            model=\"<Replace with the name of your deployment>\"\n",
    "        )\n",
    "        embedding = response.data[0].embedding\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd5119-4d36-4103-9030-a07e57443f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "apikey = \"<Replace with your Azure OpenAI key>\"\n",
    "endpoint = \"<Replace with your Azure OpenAI endpoint>\"\n",
    "\n",
    "#See note below to find value for api_version\n",
    "client = AzureOpenAI(\n",
    "  api_key = apikey,  \n",
    "  api_version = \"<Replace with the desired api version. Ex: '2024-06-01'>\",\n",
    "  azure_endpoint = endpoint\n",
    ")\n",
    "\n",
    "#Embedding the entire document will take a few moments\n",
    "print(\"Generating embeddings...\")\n",
    "embedding_array = create_embeddings(client, chunks)\n",
    "print(\"Embeddings complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b757e3b-79d1-42cd-b9d7-1d1938ba1fdd",
   "metadata": {},
   "source": [
    "**Note:** Visit https://learn.microsoft.com/en-us/azure/ai-services/openai/reference to find the latest versions of the api. It's recommended to use the latest version of *Data Plane - Inference*. An incorrect version could lead to an opaque 'Deployment Not Found' error message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b39655-4407-44d7-baa1-f9fcfeb3de1f",
   "metadata": {},
   "source": [
    "Now we can use the original text along with it's associated embedding to create documents ready for ingestion into our couchbase server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0171b-610f-445d-99a1-31f0a31bef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_dicts(texts, embeddings):\n",
    "    documents_to_insert = [\n",
    "                {\n",
    "                    'text': text,\n",
    "                    'embedding': vector,\n",
    "                        }\n",
    "                for text, vector in zip(\n",
    "                    texts, embeddings\n",
    "                )\n",
    "        ]\n",
    "    return documents_to_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf53b2-2f13-4cff-afe1-b953283e50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = format_to_dicts(chunks, embedding_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b443237e-7e6a-4e14-b5fa-5dc33f95b634",
   "metadata": {},
   "source": [
    "## Initializing Couchbase Connection\n",
    "\n",
    "**Note:** Before this step, make sure to create a Couchbase type bucket called \"CouchbaseWhitepaper\". For information on creating buckets in Couchbase, visit https://docs.couchbase.com/server/current/manage/manage-buckets/create-bucket.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8d8b4-a724-4ddd-a36d-b5a697c60a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "from couchbase.options import ClusterOptions, SearchOptions\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "\n",
    "#See note below for information about Couchbase credentials\n",
    "username = \"<Replace with your Couchbase username>\"\n",
    "password = \"<Replace with your Couchbase password\"\n",
    "connection_string = \"<Replace with your connection string>\"\n",
    "\n",
    "auth = PasswordAuthenticator(username, password)\n",
    "options = ClusterOptions(auth)\n",
    "\n",
    "cluster = Cluster(connection_string, options)\n",
    "\n",
    "#Wait until cluster is ready\n",
    "cluster.wait_until_ready(timedelta(seconds=5))\n",
    "\n",
    "bucket = cluster.bucket(\"CouchbaseWhitepaper\")\n",
    "scope = bucket.scope(\"_default\")\n",
    "collection = scope.collection(\"_default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c380a1-1e00-4cf0-ae23-d8a3b806ce6c",
   "metadata": {},
   "source": [
    "**Note:** Visit https://docs.couchbase.com/python-sdk/current/hello-world/start-using-sdk.html for information on your Couchbase credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39baff-e16c-4bc4-aa48-c2b2afc6d476",
   "metadata": {},
   "source": [
    "## Uploading Documents to Couchbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889f05d-b07b-4bc8-ab5b-110ded1628a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def batch_insert(docs, collection, batch_size=10):\n",
    "    for i in range(0,len(docs),batch_size):\n",
    "        batch = docs[i:i + batch_size]\n",
    "        docs_with_ids = {}\n",
    "        for doc in batch:\n",
    "            docs_with_ids[str(uuid.uuid4())] = doc\n",
    "        try:\n",
    "            collection.upsert_multi(docs_with_ids)\n",
    "        except Exception as e:\n",
    "            f\"Encountered exception: (e) while upserting documents.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b327b-75e7-4c16-b472-f7def7467577",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_insert(docs, collection, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b566fe-05e6-4076-94d9-52ce0dbc9eb6",
   "metadata": {},
   "source": [
    "## Creating Couchbase Search Index\n",
    "\n",
    "Before performing a vector search in Couchbase, it is first required to create an index on the collection containing the desired documents. This can be through the Python SDK, as in this tutorial, or in the Couchbase UI.\n",
    "\n",
    "**Note:** Visit https://docs.couchbase.com/server/current/vector-search/create-vector-search-index-ui.html for more information on index creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274723d-69a2-4549-a197-f240c586aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('index_parameters.json', 'r') as file:\n",
    "    index_params = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0285d650-1368-4084-b170-0def336010db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from couchbase.management.search import SearchIndex\n",
    "\n",
    "index_manager = scope.search_indexes()\n",
    "index_manager.upsert_index(\n",
    "    SearchIndex(\n",
    "                    \"VectorIndex\",\n",
    "                    params=index_params,\n",
    "                    source_name=\"CouchbaseWhitepaper\",\n",
    "                ),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08771d4a-fac4-442f-b2eb-104a8ff3ee8f",
   "metadata": {},
   "source": [
    "## Perform a Vector Search on Our Embedded Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84264ade-65c8-4b3a-a191-58bed0d3baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchbase.search as search\n",
    "from couchbase.vector_search import VectorQuery, VectorSearch\n",
    "\n",
    "def search_by_vector(\n",
    "        scope,\n",
    "        query_vector,\n",
    "        top_k=5,\n",
    "        score_threshold=0.0\n",
    "):\n",
    "\n",
    "    search_req = search.SearchRequest.create(\n",
    "        VectorSearch.from_vector_query(\n",
    "            VectorQuery(\n",
    "                'embedding',\n",
    "                query_vector,\n",
    "                top_k,\n",
    "            )\n",
    "        )\n",
    "    ) \n",
    "    try:\n",
    "        search_iter = scope.search(\n",
    "                \"VectorIndex\",\n",
    "                search_req,\n",
    "                SearchOptions(limit=top_k, collections=[\"_default\"],fields=['*']),\n",
    "            )\n",
    "\n",
    "        docs = []\n",
    "        for row in search_iter.rows():\n",
    "            text = row.fields.pop('text')\n",
    "            score = row.score\n",
    "            doc = {\"content\":text, \"score\":score}\n",
    "            if score >= score_threshold:\n",
    "                docs.append(doc)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Search failed with error: {e}\")\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da05f9e-e25c-498c-9954-042af18e4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"How do I query documents in couchbase?\"\n",
    "query_embedding = create_embeddings(client, [query_string])[0]\n",
    "print(search_by_vector(scope,query_embedding)[0]['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
